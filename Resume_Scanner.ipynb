{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume_Scanner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzXJ04FUWpODhlQI4/YbyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigamharshit/Resume_Scanner/blob/main/Resume_Scanner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Dependencies\n",
        "!pip install docx2txt\n",
        "import docx2txt  # this library converts document file to text\n",
        "\n",
        "# docx2txt.process() converts the docx file to text and return text\n",
        "\n",
        "# give the path of Job description file\n",
        "job_description = docx2txt.process('/content/Job_Description.docx')  \n",
        "# give the path of resume 1\n",
        "resume_1 = docx2txt.process('/content/Resume_1.docx')\n",
        "# give the path of resume 1\n",
        "resume_2 = docx2txt.process('/content/Resume_2.docx')\n",
        "\n",
        "\"\"\" CountVectorizer is a great tool provided by the scikit-learn library in Python. \n",
        "    It is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\n",
        "    This is helpful when we have multiple such texts, and we wish to convert each word in each text into vectors (for using in further text analysis)\"\"\"\n",
        "\n",
        "content = [ job_description, resume_1, resume_2]\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "matrix = cv.fit_transform(content)\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_matrix = cosine_similarity(matrix)\n",
        "print(\"\\nSimilarity Matrix is :\\n\",similarity_matrix)\n",
        "print()\n",
        "\n",
        "if(similarity_matrix[1][0] > similarity_matrix[2][0]):\n",
        "  print(\"Resume 1 is better\")\n",
        "elif(similarity_matrix[1][0] < similarity_matrix[2][0]):\n",
        "  print(\"Resume 2 is better\")\n",
        "else:\n",
        "  print(\"Both are similar\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5H8Bzkl67rK",
        "outputId": "713d96c4-6361-4697-8bb1-d80baeae3c5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.7/dist-packages (0.8)\n",
            "\n",
            "Similarity Matrix is :\n",
            " [[1.         0.46526219 0.59841122]\n",
            " [0.46526219 1.         0.42858388]\n",
            " [0.59841122 0.42858388 1.        ]]\n",
            "\n",
            "Resume 2 is better\n"
          ]
        }
      ]
    }
  ]
}